{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parser.add_argument('--run_id', type=str, default='', help='run id')\n",
    "parser.add_argument('--rand_seed', type=int, default='848', help='graph-level random seed for tensorflow')\n",
    "parser.add_argument('--assay_name', type=str, required=True, help='assay name, e.g. nr-ar, sr-are, ...')\n",
    "parser.add_argument('--data_dir', type=str, required=True, help='name of directory to find train, test, and score data files')\n",
    "parser.add_argument('--data_file_ext', type=str, default='data', help='file extension, exluduing the period (e.g. ''fp'', ''data'', etc)')\n",
    "parser.add_argument('--loss_balance', action='store_false', help='adjust loss function to account for unbalanced dataset, default = true')\n",
    "parser.add_argument('--kernel_reg_const', type=float, default=0.1, help='L2 kernel regularization constant')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='batch size. default = 1 (SGD)')\n",
    "parser.add_argument('--num_epochs', type=int, default=1, help='number of epochs (passes through entire training set)')\n",
    "parser.add_argument('--node_array', nargs='*', required=True, help='sizes of hidden layers in the neural network. use 0 for a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter space\n",
    "\n",
    "run_id = 0\n",
    "rand_seed = 848\n",
    "assay_name = 'nr-ahr'\n",
    "data_dir = 'data_pcfp_ext'\n",
    "data_file_ext = 'features'\n",
    "loss_balances = (True,) # (True, False)\n",
    "scales = [0.1]\n",
    "batch_sizes = [100]\n",
    "num_epochs = [4]\n",
    "node_arrays = set()\n",
    "\n",
    "node_arrays.add((0)) # no hidden layers\n",
    "\n",
    "num_nodes = [256, 512, 1024]\n",
    "num_hidden_layers = [1, 3, 5]\n",
    "for nl in num_hidden_layers:\n",
    "    combinations = list(it.combinations_with_replacement(num_nodes,nl))\n",
    "    for combination in combinations:\n",
    "        permutations = list(it.permutations(combination))\n",
    "        for node_array in permutations:\n",
    "            node_arrays.add(node_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance(file, run_id, rand_seed, assay_name, data_dir, data_file_ext, loss_balance, scale, batch_size, epoch, node_array):\n",
    "    '''\n",
    "    Arguments: hyperparameters\n",
    "        file: str\n",
    "        run_id: int\n",
    "        rand_seed: int\n",
    "        assay_name: str\n",
    "        data_dir: str\n",
    "        data_file_ext: str\n",
    "        loss_balance: bool\n",
    "        scale: float\n",
    "        batch_size: int\n",
    "        epoch: int\n",
    "        node_array: list of int\n",
    "    \n",
    "    Return: string command for running 'file' with specified parameters.\n",
    "        If parsing the parameters somehow fails, returns None.\n",
    "    '''\n",
    "    try:\n",
    "        if loss_balance is True:\n",
    "            loss_balance = '--loss_balance'\n",
    "        else:\n",
    "            loss_balance = ''\n",
    "\n",
    "        node_array_str = ''\n",
    "        # print(type(node_array))\n",
    "        if type(node_array) == tuple:\n",
    "            for c in node_array:\n",
    "                node_array_str += str(c) + ' '\n",
    "        elif type(node_array) == int:\n",
    "            node_array_str = str(node_array)\n",
    "        else:\n",
    "            node_array_str = 0\n",
    "            print('Cound not parse node_array. Returning None')\n",
    "            return None\n",
    "\n",
    "        return 'python %s --run_id %s --rand_seed %s --assay_name %s --data_dir %s --data_file_ext %s %s --kernel_reg_const %s --batch_size %s --num_epochs %s --node_array %s' % (file, str(run_id), str(rand_seed), assay_name,\n",
    "               data_dir, data_file_ext, loss_balance, str(scale),\n",
    "               str(batch_size), str(epoch), node_array_str)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_hyperparameter_tuning_script_file = 'hyperparameter_tuning_script'\n",
    "\n",
    "file = 'DNN-tensorflow-tuning.py'\n",
    "\n",
    "with open(DNN_hyperparameter_tuning_script_file, 'w') as f:\n",
    "    for loss_balance in loss_balances:\n",
    "        for scale in scales:\n",
    "            for batch_size in batch_sizes:\n",
    "                for epoch in num_epochs:\n",
    "                    for node_array in node_arrays:\n",
    "                        out = instance(file, run_id, rand_seed, assay_name, data_dir, data_file_ext, loss_balance, scale, batch_size, epoch, node_array)\n",
    "                        if out != None:\n",
    "                            f.write(out + '\\n')\n",
    "                            run_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n"
     ]
    }
   ],
   "source": [
    "print(run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
